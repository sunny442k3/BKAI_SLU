{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CoX8Ajymovd"
      },
      "outputs": [],
      "source": [
        "!pip install transformers soundfile torchmetrics gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "def drive_download(idx, output):\n",
        "    url = 'https://drive.google.com/uc?id=' + idx\n",
        "    gdown.download(url, output, quiet=False)\n",
        "drive_download(\"1ZepptsTrVSjQEx-dpBBmQ2b7xYFLn_64\", \"public_test.zip\")"
      ],
      "metadata": {
        "id": "CymJ6TaMBcEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip ./public_test.zip -d ./dataset"
      ],
      "metadata": {
        "id": "ZJZDIHlnBeFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r ./drive/MyDrive/checkpoint/checkpoint_slu.pt ./"
      ],
      "metadata": {
        "id": "cwtuQou4CRXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import utils\n",
        "from trainer import Trainer\n",
        "from model import BertSLU\n",
        "from functools import partial\n",
        "from dataset import BertDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "tpqlqXOGnCLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate(tokenizer, is_train, batch):\n",
        "    inputs = tokenizer([i[\"text\"] for i in batch], return_tensors=\"pt\", padding=\"longest\")\n",
        "    if not is_train:\n",
        "        return inputs, torch.zeros_like(inputs[\"input_ids\"]), torch.zeros(inputs[\"input_ids\"].size(0))\n",
        "    seq_len = inputs[\"input_ids\"].size(1)\n",
        "    token_labels = torch.stack([\n",
        "        torch.tensor(i[\"token_label\"] + [-100]*(seq_len - len(i[\"token_label\"]))) for i in batch\n",
        "    ])\n",
        "    intent_labels = torch.tensor([i[\"intent_label\"] for i in batch])\n",
        "    return inputs, token_labels, intent_labels"
      ],
      "metadata": {
        "id": "eN73cW1enEKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(annotation_path, token_label_path, batch_size=2, test_size=0.3):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "    annotations = utils.load_annotation(annotation_path)\n",
        "    all_intent = [i[\"intent\"] for i in annotations]\n",
        "    all_text = [i[\"sentence\"] for i in annotations]\n",
        "    all_label = utils.load_json(token_label_path)\n",
        "    all_label = [all_label, all_intent]\n",
        "    dataset = BertDataset(all_text, all_label, utils.MAP_INTENT)\n",
        "    N = len(dataset)\n",
        "    train_size = int(N * (1-test_size))\n",
        "    train_set, valid_set = torch.utils.data.random_split(dataset, [train_size, N-train_size])\n",
        "    train_loader = DataLoader(\n",
        "        train_set,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=partial(custom_collate, tokenizer, True)\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        valid_set,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=partial(custom_collate, tokenizer, True)\n",
        "    )\n",
        "    return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "6mVloO5enEMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_test_loader(test_path, batch_size=2):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
        "    sequences = utils.load_json(test_path)\n",
        "    id_seqs = [k for k, v in sequences.items()]\n",
        "    seqs = [v for k, v in sequences.items()]\n",
        "    dataset = BertDataset(seqs)\n",
        "    test_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=partial(custom_collate, tokenizer, False)\n",
        "    )\n",
        "    return test_loader, id_seqs, seqs"
      ],
      "metadata": {
        "id": "a7nbfvJU63f5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, valid_loader = get_loader(\"./dataset/train.jsonl\", \"./dataset/bert_token_labels.json\", 16)\n",
        "print(f\"Len train_loader: {len(train_loader)} - Len valid_loader: {len(valid_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ4DbGdjnEPR",
        "outputId": "822ac807-7bb1-4f43-ae56-514d2a712615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len train_loader: 328 - Len valid_loader: 141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader, test_file_id, all_seqs = get_test_loader(\"./dataset/test_sentences.json\", 8)\n",
        "len(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbAISnQTBqEW",
        "outputId": "89b58d24-b5c9-417a-97b2-4d15c37915f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class config:\n",
        "    epochs = 20\n",
        "    checkpoint_path = \"./checkpoint/checkpoint_bert.pt\"\n",
        "    learning_rate = 5e-5\n",
        "    adam_eps = 1e-8\n",
        "    warmup_steps = 2000\n",
        "    weight_decay = 0.005"
      ],
      "metadata": {
        "id": "PfOxuR5nnEHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertSLU(15, 9)\n",
        "print(f\"Num of param:\", sum(p.numel() for p in model.parameters()))\n",
        "optimizer = torch.optim.AdamW(utils.weight_decay(model, config.weight_decay), lr=config.learning_rate, eps=config.adam_eps)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrz_jhkRnERs",
        "outputId": "be94df18-75e3-466d-b271-b1f702ac6b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of param: 135016728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model, optimizer, criterion, amp=True, device=device)\n",
        "# trainer.load_checkpoint(\"./checkpoint/checkpoint_bert.pt\") Load checkpoint if wanna continue training\n",
        "trainer.fit(train_loader, valid_loader, config.epochs, config.checkpoint_path)"
      ],
      "metadata": {
        "id": "-knZKV8BnEUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubTk8891gdeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUiLWtzAgdri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens, all_intents = trainer.test(test_loader)\n",
        "len(all_tokens), len(all_intents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEhRLDy7Cnhi",
        "outputId": "0cc234e9-5a42-4482-f4aa-2fd9a21e9518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 163 / 163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1299, 1299)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW5JCiDBFWsA",
        "outputId": "3cf6eab9-e556-4499-cc43-4372540904ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWbYXRtVCors",
        "outputId": "31382acb-b525-490a-a3b1-6c7e3e1c4110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 5, 0, 6, 6, 6, 0, 5, 0, 8, 0, 0, 0, 0, 0, 0],\n",
              " [0, 5, 2, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 5, 5, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
              " [0, 5, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 5, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_seqs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUAHHrXGCouI",
        "outputId": "3f09a8e9-68e7-43e3-8aa7-d0fd5e9838f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tăng ở cầu thang a mức tăng là 41',\n",
              " 'tắt camera của huy đi cho tôi',\n",
              " 'kiểm tra cho mình vào lúc 15 giờ 16 phút nhé',\n",
              " 'đóng hộ anh cái cửa cuốn số 19',\n",
              " 'bật cho mình cái laptop với mình cần làm việc']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(all_seqs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-g8pC7upFRlD",
        "outputId": "5798274b-8248-41ef-fec3-5f3c2a6c54b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tăng', 'ở', 'cầu', 'thang', 'a', 'mức', 'tăng', 'là', '41']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_intents[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM_NQiBDCow3",
        "outputId": "276f4cf9-5210-4a5c-ba9c-0604c894c2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7, 3, 9, 1, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INVERSE_MAP_TOKENS = {\n",
        "    0: 'word',\n",
        "    1: 'time at',\n",
        "    2: 'device',\n",
        "    3: 'changing value',\n",
        "    4: 'scene',\n",
        "    5: 'command',\n",
        "    6: 'location',\n",
        "    7: 'duration',\n",
        "    8: 'target number'\n",
        " }\n",
        "\n",
        "INVERSE_MAP_INTENTS = {\n",
        "    0: 'Giảm độ sáng của thiết bị',\n",
        "    1: 'Đóng thiết bị',\n",
        "    2: 'Hủy hoạt cảnh',\n",
        "    3: 'Tắt thiết bị',\n",
        "    4: 'Tăng âm lượng của thiết bị',\n",
        "    5: 'Giảm mức độ của thiết bị',\n",
        "    6: 'Bật thiết bị',\n",
        "    7: 'Tăng mức độ của thiết bị',\n",
        "    8: 'Tăng nhiệt độ của thiết bị',\n",
        "    9: 'Kiểm tra tình trạng thiết bị',\n",
        "    10: 'Mở thiết bị',\n",
        "    11: 'Giảm âm lượng của thiết bị',\n",
        "    12: 'Kích hoạt cảnh',\n",
        "    13: 'Giảm nhiệt độ của thiết bị',\n",
        "    14: 'Tăng độ sáng của thiết bị'\n",
        "}"
      ],
      "metadata": {
        "id": "92ZSv_lXJR0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_label(token):\n",
        "    token = token[1:]\n",
        "    for i in range(len(token) - 1, -1, -1):\n",
        "        if token[i] != 0:\n",
        "            token = token[:i+1]\n",
        "            break\n",
        "    token += [-1]\n",
        "    map_labels = []\n",
        "    cur = 0\n",
        "    val = token[0]\n",
        "    for idx, i in enumerate(token[1:], 1):\n",
        "        if i == val:\n",
        "            continue\n",
        "        else:\n",
        "            if val != 0:\n",
        "                map_labels.append([cur, idx-1, val])\n",
        "            val = i\n",
        "            cur = idx\n",
        "    return map_labels\n",
        "\n",
        "def convert_into_output(all_tokens, all_intents, all_seqs, test_file_id, tokenizer):\n",
        "    ans = []\n",
        "    for idx in range(len(all_tokens)):\n",
        "        token = all_tokens[idx]\n",
        "        intent = all_intents[idx]\n",
        "        seq = tokenizer.tokenize(all_seqs[idx])\n",
        "        labels = collect_label(token)\n",
        "        tmp_ans = {\n",
        "            \"intent\": INVERSE_MAP_INTENTS[intent],\n",
        "            \"file\": test_file_id[idx]\n",
        "        }\n",
        "        entities = []\n",
        "        # print(labels)\n",
        "        # print(seq)\n",
        "        # return\n",
        "        for label in labels:\n",
        "            if label[-1] == 0:\n",
        "                continue\n",
        "            sub_text = seq[label[0]: label[1]+1]\n",
        "            sub_text = tokenizer.decode(\n",
        "                tokenizer.convert_tokens_to_ids(sub_text), skip_special_tokens=True\n",
        "            )\n",
        "            tmp_add = {\"type\": INVERSE_MAP_TOKENS[label[-1]], \"filler\": sub_text}\n",
        "            check = list(filter(lambda x: tmp_add[\"type\"] == x[\"type\"] and tmp_add[\"filler\"] == x[\"filler\"], entities))\n",
        "            if len(check):\n",
        "                continue\n",
        "            entities += [tmp_add]\n",
        "        tmp_ans[\"entities\"] = entities\n",
        "        ans.append(tmp_ans)\n",
        "        print(\"\\r\", end=\"\")\n",
        "        print(f\"\\r {idx+1} / {len(all_tokens)}\", end=\"\")\n",
        "    return ans"
      ],
      "metadata": {
        "id": "p-QhP_ztFwzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = convert_into_output(all_tokens, all_intents, all_seqs, test_file_id, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_COeQeYzINjD",
        "outputId": "a7210947-07b3-4b41-f9fa-38385a54c0cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1299 / 1299"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fBarcgXLXnr",
        "outputId": "568ec474-3a40-4f06-9ba3-31901af5ccd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'intent': 'Tăng mức độ của thiết bị',\n",
              "  'file': 'TGZD2rv26WxpkV9LRAxwmVb.wav',\n",
              "  'entities': [{'type': 'command', 'filler': 'tăng'},\n",
              "   {'type': 'location', 'filler': 'cầu thang a'},\n",
              "   {'type': 'target number', 'filler': '41'}]},\n",
              " {'intent': 'Tắt thiết bị',\n",
              "  'file': 'QgEpeOnXqmu2gclgZxvGaVo.wav',\n",
              "  'entities': [{'type': 'command', 'filler': 'tắt'},\n",
              "   {'type': 'device', 'filler': 'camera của'},\n",
              "   {'type': 'location', 'filler': 'huy'}]},\n",
              " {'intent': 'Kiểm tra tình trạng thiết bị',\n",
              "  'file': 'OswACb2vqKb3OjMJkqveMn2.wav',\n",
              "  'entities': [{'type': 'command', 'filler': 'kiểm tra'},\n",
              "   {'type': 'time at', 'filler': '15 giờ 16 phút'}]},\n",
              " {'intent': 'Đóng thiết bị',\n",
              "  'file': 'grFpJzV3KfLoCwTY8Wh2o9K.wav',\n",
              "  'entities': [{'type': 'command', 'filler': 'đóng'},\n",
              "   {'type': 'device', 'filler': 'cửa cuốn số 19'}]},\n",
              " {'intent': 'Bật thiết bị',\n",
              "  'file': 'bwFuSjwUxFmpjSJTE7X9M2N.wav',\n",
              "  'entities': [{'type': 'command', 'filler': 'bật'},\n",
              "   {'type': 'device', 'filler': 'laptop'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"./submission.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for line in ans:\n",
        "        json.dump(line, f)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "id": "HvN-RjVNL_T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tBMr_GrpEVpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_N-3adxegs7n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}